{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"20172642_신형담_XOR.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNEmvEYpfVQvvnDjNRoANpI"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":35,"metadata":{"id":"qR3s5e6_VgFW","executionInfo":{"status":"ok","timestamp":1655012871503,"user_tz":-540,"elapsed":427,"user":{"displayName":"HyungDam Shin","userId":"00841319868851649189"}}},"outputs":[],"source":["import numpy as np\n","\n","# 수치미분 함수\n","def numerical_derivative(f, x):\n","    delta_x = 1e-4 # 0.0001\n","    grad = np.zeros_like(x)\n","    \n","    it = np.nditer(x, flags=['multi_index'], op_flags=['readwrite'])\n","    \n","    while not it.finished:\n","        idx = it.multi_index\n","        tmp_val = x[idx]\n","        x[idx] = float(tmp_val) + delta_x\n","        fx1 = f(x)\n","        \n","        x[idx] = float(tmp_val) - delta_x \n","        fx2 = f(x)\n","        grad[idx] = (fx1 - fx2) / (2*delta_x)\n","        \n","        x[idx] = tmp_val \n","        it.iternext()\n","        \n","    return grad\n","\n","# sigmoid 함수\n","def sigmoid(x):\n","    return 1 / (1+np.exp(-x))"]},{"cell_type":"code","source":["class LogicGate:\n","    def __init__(self, gate_name, xdata, tdata):\n","        self.name = gate_name\n","        \n","        # 입력 데이터, 정답 데이터 초기화\n","        self.__xdata = xdata.reshape(4, 2)\n","        self.__tdata = tdata.reshape(4, 1)\n","        \n","        # 2층 hidden layer unit : 6개 가정,  가중치 W2, 바이어스 b2 초기화\n","        self.__W2 = np.random.rand(2, 6)\n","        self.__b2 = np.random.rand(6)\n","        \n","        # 3층 output layer unit : 1 개 , 가중치 W3, 바이어스 b3 초기화\n","        self.__W3 = np.random.rand(6, 1)\n","        self.__b3 = np.random.rand(1)\n","        \n","        # 학습률 learning rate 초기화\n","        self.__learning_rate = 1e-2\n","        \n","        print(self.name + \" object is created\")\n","        \n","    def feed_forward(self):\n","        delta = 1e-7\n","        \n","        z2 = np.dot(self.__xdata, self.__W2) + self.__b2  # 은닉층의 선형회귀 값\n","        a2 = sigmoid(z2)                                  # 은닉층의 출력\n","        \n","        z3 = np.dot(a2, self.__W3) + self.__b3            # 출력층의 선형회귀 값\n","        y = a3 = sigmoid(z3)                              # 출력층의 출력\n","        \n","        # cross-entropy \n","        return  -np.sum( self.__tdata*np.log(y+delta) + (1-self.__tdata)*np.log((1-y)+delta) )    \n","    \n","    def loss_val(self):\n","        delta = 1e-7\n","        \n","        z2 = np.dot(self.__xdata, self.__W2) + self.__b2  # 은닉층의 선형회귀 값\n","        a2 = sigmoid(z2)                                  # 은닉층의 출력\n","        \n","        z3 = np.dot(a2, self.__W3) + self.__b3            # 출력층의 선형회귀 값\n","        y = a3 = sigmoid(z3)                              # 출력층의 출력\n","        \n","        # cross-entropy\n","        return  -np.sum( self.__tdata*np.log(y+delta) + (1-self.__tdata)*np.log((1-y)+delta) )\n","        \n","    def train(self):\n","        f = lambda x : self.feed_forward()\n","        print(\"Initial loss value = \", self.loss_val())\n","        \n","        for step in  range(20001):\n","            self.__W2 -= self.__learning_rate * numerical_derivative(f, self.__W2)\n","            self.__b2 -= self.__learning_rate * numerical_derivative(f, self.__b2)\n","            self.__W3 -= self.__learning_rate * numerical_derivative(f, self.__W3)\n","            self.__b3 -= self.__learning_rate * numerical_derivative(f, self.__b3)\n","            \n","            if (step % 1000 == 0):\n","                print(\"step = \", step, \"  , loss value = \", self.loss_val())\n","    \n","    def predict(self, xdata):\n","        z2 = np.dot(xdata, self.__W2) + self.__b2         # 은닉층의 선형회귀 값\n","        a2 = sigmoid(z2)                                  # 은닉층의 출력\n","        \n","        z3 = np.dot(a2, self.__W3) + self.__b3            # 출력층의 선형회귀 값\n","        y = a3 = sigmoid(z3)                              # 출력층의 출력\n","        \n","        if y > 0.5:\n","            result = 1  # True\n","        else:\n","            result = 0  # False\n","            \n","        return y, result"],"metadata":{"id":"PS0_7QJlVu2I","executionInfo":{"status":"ok","timestamp":1655012872580,"user_tz":-540,"elapsed":3,"user":{"displayName":"HyungDam Shin","userId":"00841319868851649189"}}},"execution_count":36,"outputs":[]},{"cell_type":"code","source":["xdata = np.array([ [0, 0], [0, 1], [1, 0], [1, 1] ])\n","tdata = np.array([0, 1, 1, 0])\n","\n","xor_obj = LogicGate(\"XOR\", xdata, tdata)\n","xor_obj.train()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b1Ej7oDqV3M3","executionInfo":{"status":"ok","timestamp":1655012913644,"user_tz":-540,"elapsed":40510,"user":{"displayName":"HyungDam Shin","userId":"00841319868851649189"}},"outputId":"34c870ff-f3d5-4f85-8a38-9d4916914301"},"execution_count":37,"outputs":[{"output_type":"stream","name":"stdout","text":["XOR object is created\n","Initial loss value =  7.164464393177543\n","step =  0   , loss value =  7.01167082206538\n","step =  1000   , loss value =  2.759963427518775\n","step =  2000   , loss value =  2.739752133386367\n","step =  3000   , loss value =  2.6915402522562193\n","step =  4000   , loss value =  2.570355196656134\n","step =  5000   , loss value =  2.323034443903422\n","step =  6000   , loss value =  1.988533076480374\n","step =  7000   , loss value =  1.6006176387488158\n","step =  8000   , loss value =  1.179505528753082\n","step =  9000   , loss value =  0.8249304293294477\n","step =  10000   , loss value =  0.5831557815856121\n","step =  11000   , loss value =  0.4291118649924459\n","step =  12000   , loss value =  0.32951976348481793\n","step =  13000   , loss value =  0.26245741767513614\n","step =  14000   , loss value =  0.21530458923423304\n","step =  15000   , loss value =  0.1808421611465229\n","step =  16000   , loss value =  0.15481145407262187\n","step =  17000   , loss value =  0.134598385796521\n","step =  18000   , loss value =  0.11853401710523753\n","step =  19000   , loss value =  0.10551378169309081\n","step =  20000   , loss value =  0.09478285557593381\n"]}]},{"cell_type":"code","source":["test_data = np.array([ [0, 0], [0, 1], [1, 0], [1, 1] ])\n","\n","for data in test_data:\n","    print(xor_obj.predict(data))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JQhpfQPDWDnl","executionInfo":{"status":"ok","timestamp":1655012913645,"user_tz":-540,"elapsed":10,"user":{"displayName":"HyungDam Shin","userId":"00841319868851649189"}},"outputId":"dd8021dc-bc94-404d-aec9-a97dae328ddc"},"execution_count":38,"outputs":[{"output_type":"stream","name":"stdout","text":["(array([0.00592093]), 0)\n","(array([0.97657793]), 1)\n","(array([0.97253585]), 1)\n","(array([0.03660876]), 0)\n"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"7Af6BdeXXq6V","executionInfo":{"status":"ok","timestamp":1655012842983,"user_tz":-540,"elapsed":25,"user":{"displayName":"HyungDam Shin","userId":"00841319868851649189"}}},"execution_count":33,"outputs":[]}]}